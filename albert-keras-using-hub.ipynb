{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/google-research/albert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# https://www.kaggle.com/igetii/bert-keras/notebook?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 18 16:47:54 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.48.02    Driver Version: 440.48.02    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 2080    Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 28%   43C    P0    17W / 245W |      0MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('albert')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import zipfile\n",
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "\n",
    "from tokenization import FullTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config,)\n",
    "\n",
    "# Params for albert model and tokenization\n",
    "# bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "albert_path = 'https://tfhub.dev/google/albert_base/1'\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('files/train.csv', index_col='id')\n",
    "val_df = pd.read_csv('files/valid.csv', index_col='id')\n",
    "test_df = pd.read_csv('files/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam has an everlast treat each nite before bed...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The product is as it says. I keep an eye on it...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My Kitty thinks these are treats! He loves the...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the third or fourth time that we've or...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Put this on both my dogs. And they are scratch...</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text label\n",
       "id                                                         \n",
       "0   Sam has an everlast treat each nite before bed...  dogs\n",
       "1   The product is as it says. I keep an eye on it...  dogs\n",
       "2   My Kitty thinks these are treats! He loves the...  dogs\n",
       "3   This is the third or fourth time that we've or...  dogs\n",
       "4   Put this on both my dogs. And they are scratch...  dogs"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder().fit(pd.concat([train_df['label'], val_df['label']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_pred = pd.concat([train_df['text'], val_df['text']]).values, test_df['text'].values\n",
    "y_train_val = label_encoder.fit_transform(pd.concat([train_df['label'], val_df['label']]))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,y_train_val, test_size=0.2, random_state=0, stratify = y_train_val\n",
    "        )\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_val,y_val, test_size=0.5, random_state=0\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55528\n",
      "6941\n",
      "6941\n",
      "17353\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))\n",
    "print(len(X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train\n",
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "train_label = y_train\n",
    "\n",
    "val_text = X_val\n",
    "val_text = [' '.join(t.split()[0:max_seq_length]) for t in val_text]\n",
    "val_text = np.array(val_text, dtype=object)[:, np.newaxis]\n",
    "val_label = y_val\n",
    "\n",
    "test_text = X_test\n",
    "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = y_test\n",
    "\n",
    "pred_text = X_pred\n",
    "pred_text = [' '.join(t.split()[0:max_seq_length]) for t in pred_text]\n",
    "pred_text = np.array(pred_text, dtype=object)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "#from tensorflow.keras import backend as K\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class AlbertLayer(Layer):\n",
    "    \n",
    "    '''AlbertLayer which support next output_representation param:\n",
    "    \n",
    "    pooled_output: the first CLS token after adding projection layer () with shape [batch_size, 768]. \n",
    "    sequence_output: all tokens output with shape [batch_size, max_length, 768].\n",
    "    mean_pooling: mean pooling of all tokens output [batch_size, max_length, 768].\n",
    "    \n",
    "    \n",
    "    You can simple fine-tune last n layers in ALBERT with n_fine_tune_layers parameter. For view trainable parameters call model.trainable_weights after creating model.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_fine_tune_layers=10, tf_hub = None, output_representation = 'pooled_output', trainable = False, **kwargs):\n",
    "        \n",
    "        print('__init__ is called')\n",
    "        \n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.is_trainble = trainable\n",
    "        self.output_size = 768\n",
    "        self.tf_hub = tf_hub\n",
    "        self.output_representation = output_representation\n",
    "        self.supports_masking = True\n",
    "        \n",
    "        super(AlbertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print('build is called')\n",
    "\n",
    "        self.albert = hub.Module(\n",
    "            self.tf_hub,\n",
    "            trainable=self.is_trainble,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        variables = list(self.albert.variable_map.values())\n",
    "#         print(variables)\n",
    "        if self.is_trainble:\n",
    "            # 1 first remove unused layers\n",
    "            trainable_vars = [var for var in variables if not \"/cls/\" in var.name]\n",
    "#             trainable_vars = [var for var in variables]\n",
    "            \n",
    "            \n",
    "            if self.output_representation == \"sequence_output\" or self.output_representation == \"mean_pooling\":\n",
    "                # 1 first remove unused pooled layers\n",
    "                trainable_vars = [var for var in trainable_vars if not \"/pooler/\" in var.name]\n",
    "                \n",
    "            # Select how many layers to fine tune\n",
    "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "            \n",
    "            # Add to trainable weights\n",
    "            for var in trainable_vars:\n",
    "                self._trainable_weights.append(var)\n",
    "\n",
    "            # Add non-trainable weights\n",
    "            for var in self.albert.variables:\n",
    "                if var not in self._trainable_weights:\n",
    "                    self._non_trainable_weights.append(var)\n",
    "                \n",
    "        else:\n",
    "             for var in variables:\n",
    "                self._non_trainable_weights.append(var)\n",
    "                \n",
    "\n",
    "        super(AlbertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print('call is called')\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        albert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.albert(inputs=albert_inputs, signature=\"tokens\", as_dict=True)\n",
    "        \n",
    "        if self.output_representation == \"pooled_output\":\n",
    "            pooled = result[\"pooled_output\"]\n",
    "            \n",
    "        elif self.output_representation == \"mean_pooling\":\n",
    "            result_tmp = result[\"sequence_output\"]\n",
    "        \n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result_tmp, input_mask)\n",
    "            \n",
    "        elif self.output_representation == \"sequence_output\":\n",
    "            \n",
    "            pooled = result[\"sequence_output\"]\n",
    "       \n",
    "        return pooled\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        \n",
    "        if self.output_representation == 'sequence_output':\n",
    "            inputs = [K.cast(x, dtype=\"bool\") for x in inputs]\n",
    "            mask = inputs[1]\n",
    "            \n",
    "            return mask\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.output_representation == \"sequence_output\":\n",
    "            return (input_shape[0][0], input_shape[0][1], self.output_size)\n",
    "        else:\n",
    "            return (input_shape[0][0], self.output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_seq_length, tf_hub, n_classes, n_fine_tune): \n",
    "    in_id = keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    albert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    albert_output = AlbertLayer(n_fine_tune_layers=n_fine_tune, tf_hub = tf_hub, output_representation = 'mean_pooling', trainable = True)(albert_inputs)\n",
    "    drop = keras.layers.Dropout(0.3)(albert_output)\n",
    "    dense = keras.layers.Dense(256, activation='sigmoid')(drop)\n",
    "    drop = keras.layers.Dropout(0.3)(dense)\n",
    "    dense = keras.layers.Dense(64, activation='sigmoid')(drop)\n",
    "    pred = keras.layers.Dense(n_classes, activation='softmax')(dense)\n",
    "    \n",
    "    model = keras.models.Model(inputs=albert_inputs, outputs=pred)\n",
    "    Adam = keras.optimizers.Adam(lr = 0.00008)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam, metrics=['sparse_categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "#     return z_imbd\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Class :  6\n",
      "__init__ is called\n",
      "build is called\n",
      "self._spec\n",
      "call is called\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_layer_2 (AlbertLayer)    (None, 768)          11812272    input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 768)          0           albert_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          196864      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           16448       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            390         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,025,974\n",
      "Trainable params: 11,306,694\n",
      "Non-trainable params: 719,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(label_encoder.classes_)\n",
    "print('Num Class : ', n_classes)\n",
    "n_fine_tune_layers = 48\n",
    "\n",
    "model = build_model(max_seq_length, albert_path, n_classes, n_fine_tune_layers)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module(tf_hub):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    albert_module =  hub.Module(tf_hub)\n",
    "    tokenization_info = albert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run(\n",
    "            [\n",
    "                tokenization_info[\"vocab_file\"],\n",
    "                tokenization_info[\"do_lower_case\"],\n",
    "            ]\n",
    "    )\n",
    "    \n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case, spm_model_file='albert_base_1/assets/30k-clean.model')\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    #print(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -zxvf albert_base_1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate tokenizer\n",
    "# # tokenizer = create_tokenizer_from_hub_module(albert_path)\n",
    "# tokenizer = FullTokenizer('albert_base_1/30k-clean.vocab', do_lower_case=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.tokenize(\"hi I like cat and dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._spec\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading sentence piece model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading sentence piece model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁hi', '▁', 'I', '▁like', '▁cat', '▁and', '▁dog', ',', '▁nice', '▁to', '▁meet', '▁you']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module(albert_path)\n",
    "print(tokenizer.tokenize(\"hi I like cat and dog, nice to meet you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._spec\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading sentence piece model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loading sentence piece model\n",
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:91: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c635bced8bb44449a577e15ddffaed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=55528.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677e1b8e81d64e358b98ee0120ad7924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=6941.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(albert_path)\n",
    "# tokenizer = FullTokenizer('albert_base_1/30k-clean.vocab', do_lower_case=True )\n",
    "# print('hi')\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_label)\n",
    "val_examples = convert_text_to_examples(val_text, val_label)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels\n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55528 samples, validate on 6941 samples\n",
      "Epoch 1/10\n",
      "55528/55528 [==============================] - 729s 13ms/step - loss: 0.7477 - sparse_categorical_accuracy: 0.7309 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.7774\n",
      "Epoch 2/10\n",
      "55528/55528 [==============================] - 721s 13ms/step - loss: 0.6423 - sparse_categorical_accuracy: 0.7757 - val_loss: 1.0192 - val_sparse_categorical_accuracy: 0.6496\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MONITOR = 'val_sparse_categorical_accuracy'\n",
    "print('BATCH_SIZE is {}'.format(BATCH_SIZE))\n",
    "e_stopping = EarlyStopping(monitor=MONITOR, patience=1, verbose=1, mode='max', restore_best_weights=True)\n",
    "callbacks =  [e_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "   [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data = ([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:91: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44cdb932dd74733b2a184304abd1110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=6941.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6941/6941 [==============================] - 31s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5982288722688982, 0.7722229957580566]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples = convert_text_to_examples(test_text, test_label)\n",
    "\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "model.evaluate([test_input_ids, test_input_masks, test_segment_ids], test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_examples = convert_text_to_examples(pred_text, np.zeros(len(pred_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:91: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a20dbbd08f4262930f627c55e90615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=17353.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(pred_input_ids, pred_input_masks, pred_segment_ids, pred_labels\n",
    ") = convert_examples_to_features(tokenizer, pred_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17353/17353 [==============================] - 81s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([pred_input_ids, pred_input_masks, pred_segment_ids], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = label_encoder.classes_[np.argmax(prediction, axis =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dogs', 'dogs', 'dogs', 'cats', 'cats', 'cats', 'dogs', 'dogs',\n",
       "       'dogs', 'dogs', 'dogs', 'cats', 'dogs', 'dogs', 'dogs', 'dogs',\n",
       "       'dogs', 'fish aquatic pets', 'dogs', 'cats', 'dogs', 'cats',\n",
       "       'cats', 'dogs', 'cats', 'dogs', 'fish aquatic pets', 'cats',\n",
       "       'cats', 'cats'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
