{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From bert2/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('bert2')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import zipfile\n",
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "\n",
    "from tokenization import FullTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 18 15:16:05 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.48.02    Driver Version: 440.48.02    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 2080    Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "|  0%   47C    P8    11W / 245W |    122MiB /  7982MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1810      C   ...gon2/bert/albert/albert-env/bin/python3   111MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "# !wget -q https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
    "# !wget -q https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
    "# !wget -q https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('files/train.csv', index_col='id')\n",
    "val_df = pd.read_csv('files/valid.csv', index_col='id')\n",
    "test_df = pd.read_csv('files/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55528\n",
      "6941\n",
      "6941\n",
      "17353\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(pd.concat([train_df['label'], val_df['label']]))\n",
    "\n",
    "X_train_val, X_pred = pd.concat([train_df['text'], val_df['text']]).values, test_df['text'].values\n",
    "y_train_val = label_encoder.fit_transform(pd.concat([train_df['label'], val_df['label']]))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,y_train_val, test_size=0.2, random_state=0, stratify = y_train_val\n",
    "        )\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_val,y_val, test_size=0.5, random_state=0\n",
    "        )\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))\n",
    "print(len(X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Good for keeping our large dogs on the porch; mechanism to open gate difficult to use. Easy to install, nice to look at, would buy again.',\n",
       "       'I have two guinea pigs, who reproduce, after a lot of trial and error we have settled on this bedding. We clean out their cage once a week and never have problems with smells. Best bedding out there in our opinion.',\n",
       "       'It took my cats about 5 minutes to figure out how to \"cheat\" the timer on this feeder. They can just stick their paws into the tube where the food comes out, and get food whenever they want. This product would definitely not be safe for any cat that needs have his/her food intake controlled. It might be fine for a large dog with paws too big to fit into the tube.',\n",
       "       ...,\n",
       "       'One of my cats, Pooka, has always had issues with her water bowl. She spent too much time playing in the water, dragging her very heavy water dish around the kitchen and dumping it over just to watch the water run across the floor -- and \"drowning\" her little toy plush bunnies on a daily basis for nearly four years. I could handle the playing in the water and the drowning of her toys -- but having her dump the dish every day was really getting on my nerves. I researched why some cats love to play in their water bowls and would prefer drinking water from the tap. I had heard about pet drinking fountains but never thought that water movement was what Pooka was desperately seeking. That seemed to be the problem... no water movement.The Cat-It Large Fresh & Clear Drinking Fountain was perfect! She can drink from the water spilling over the dome -- or use the bowl at the bottom. Tommy is the other cat in the family and he\\'s not particular at all about where he gets his drinking water. He loves the Cat-It fountain -- or a mud puddle. Both cats were immediately drawn to the Cat-It fountain. I had read reviews that mentioned not adding the additional food bowl to the fountain just to keep the cat chow out of the water. That made a lot of sense to me so I left it off. I did purchase the rather large plastic mat so there would be one more layer that might possibly keep Pooka from moving the fountain. It helps. She\\'s still obsessed with moving the whole unit from side to side within the confines of the mat. I remind her that the fountain is for drinking -- not playing. She ignores me and continues doing whatever she\\'s doing. The Cat-It Large Fresh & Clear Drinking Fountain has done the trick. I haven\\'t had to mop up any spilled rivulets for a month!P.S. Recently, I came across an unsent email that Pooka was planning on sending to the Hagan Company suggesting the addition of colorfully flashing disco lights under the water dome...',\n",
       "       'I purchased this for our sick cat Willy. He had lung cancer and I wanted something tomake him feel good. This product was a huge hit! I set it up in the kitchen and Willy loved it. I really think it made him more comfortable.You never know when you buy something for a cat. Are they going to walk away and actinsulted or are they going to love it.This gets a 5 star rating from my cat.If you have an older cat that needs some comfort this is an item for you.',\n",
       "       \"We put her in this during the day (while I work and my husband is sleeping). We line with puppy pads and put her bed and toys in there. She doesn't love it (yet) since she's only 8 weeks old and HATES being alone and without us. But it's a perfect size to keep her indoors and confined without having no room to play in. It's not bulky and was easy for my husband to put together.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train\n",
    "\n",
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
    "\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = X_train\n",
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "train_label = y_train\n",
    "\n",
    "val_text = X_val\n",
    "val_text = [' '.join(t.split()[0:max_seq_length]) for t in val_text]\n",
    "val_text = np.array(val_text, dtype=object)[:, np.newaxis]\n",
    "val_label = y_val\n",
    "\n",
    "test_text = X_test\n",
    "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = y_test\n",
    "\n",
    "pred_text = X_pred\n",
    "pred_text = [' '.join(t.split()[0:max_seq_length]) for t in pred_text]\n",
    "pred_text = np.array(pred_text, dtype=object)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "#from tensorflow.keras import backend as K\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "\n",
    "class BertLayer(Layer):\n",
    "    \n",
    "    '''BertLayer which support next output_representation param:\n",
    "    \n",
    "    pooled_output: the first CLS token after adding projection layer () with shape [batch_size, 768]. \n",
    "    sequence_output: all tokens output with shape [batch_size, max_length, 768].\n",
    "    mean_pooling: mean pooling of all tokens output [batch_size, max_length, 768].\n",
    "    \n",
    "    \n",
    "    You can simple fine-tune last n layers in BERT with n_fine_tune_layers parameter. For view trainable parameters call model.trainable_weights after creating model.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_fine_tune_layers=10, tf_hub = None, output_representation = 'pooled_output', trainable = False, **kwargs):\n",
    "        \n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.is_trainble = trainable\n",
    "        self.output_size = 768\n",
    "        self.tf_hub = tf_hub\n",
    "        self.output_representation = output_representation\n",
    "        self.supports_masking = True\n",
    "        \n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.bert = hub.Module(\n",
    "            self.tf_hub,\n",
    "            trainable=self.is_trainble,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        variables = list(self.bert.variable_map.values())\n",
    "        if self.is_trainble:\n",
    "            # 1 first remove unused layers\n",
    "            trainable_vars = [var for var in variables if not \"/cls/\" in var.name]\n",
    "            \n",
    "            \n",
    "            if self.output_representation == \"sequence_output\" or self.output_representation == \"mean_pooling\":\n",
    "                # 1 first remove unused pooled layers\n",
    "                trainable_vars = [var for var in trainable_vars if not \"/pooler/\" in var.name]\n",
    "                \n",
    "            # Select how many layers to fine tune\n",
    "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "            \n",
    "            # Add to trainable weights\n",
    "            for var in trainable_vars:\n",
    "                self._trainable_weights.append(var)\n",
    "\n",
    "            # Add non-trainable weights\n",
    "            for var in self.bert.variables:\n",
    "                if var not in self._trainable_weights:\n",
    "                    self._non_trainable_weights.append(var)\n",
    "                \n",
    "        else:\n",
    "             for var in variables:\n",
    "                self._non_trainable_weights.append(var)\n",
    "                \n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "        \n",
    "        if self.output_representation == \"pooled_output\":\n",
    "            pooled = result[\"pooled_output\"]\n",
    "            \n",
    "        elif self.output_representation == \"mean_pooling\":\n",
    "            result_tmp = result[\"sequence_output\"]\n",
    "        \n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result_tmp, input_mask)\n",
    "            \n",
    "        elif self.output_representation == \"sequence_output\":\n",
    "            \n",
    "            pooled = result[\"sequence_output\"]\n",
    "       \n",
    "        return pooled\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        \n",
    "        if self.output_representation == 'sequence_output':\n",
    "            inputs = [K.cast(x, dtype=\"bool\") for x in inputs]\n",
    "            mask = inputs[1]\n",
    "            \n",
    "            return mask\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.output_representation == \"sequence_output\":\n",
    "            return (input_shape[0][0], input_shape[0][1], self.output_size)\n",
    "        else:\n",
    "            return (input_shape[0][0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_seq_length, tf_hub, n_classes, n_fine_tune): \n",
    "    in_id = keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=n_fine_tune, tf_hub = tf_hub, output_representation = 'mean_pooling', trainable = True)(bert_inputs)\n",
    "    drop = keras.layers.Dropout(0.3)(bert_output)\n",
    "    dense = keras.layers.Dense(256, activation='sigmoid')(drop)\n",
    "    drop = keras.layers.Dropout(0.3)(dense)\n",
    "    dense = keras.layers.Dense(64, activation='sigmoid')(drop)\n",
    "    pred = keras.layers.Dense(n_classes, activation='softmax')(dense)\n",
    "    \n",
    "    model = keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    Adam = keras.optimizers.Adam(lr = 0.0002)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam, metrics=['sparse_categorical_accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._spec\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 768)          0           bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          196864      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           16448       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            390         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,318,592\n",
      "Trainable params: 21,477,318\n",
      "Non-trainable params: 88,841,274\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(label_encoder.classes_)\n",
    "n_fine_tune_layers = 48\n",
    "model = build_model(max_seq_length, bert_path, n_classes, n_fine_tune_layers)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module(tf_hub):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(tf_hub)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    #print(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._spec\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'i', 'like', 'cat', 'and', 'dog', ',', 'nice', 'to', 'meet', 'you']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "print(tokenizer.tokenize(\"hi I like cat and dog, nice to meet you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._spec\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:90: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e829b177f6414a878b1693ec266f4ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=55528.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4969e8a40fe0461d9f5e06607f1e2a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=6941.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_label)\n",
    "val_examples = convert_text_to_examples(val_text, val_label)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(val_input_ids, val_input_masks, val_segment_ids, val_labels\n",
    ") = convert_examples_to_features(tokenizer, val_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE is 32\n",
      "Train on 55528 samples, validate on 6941 samples\n",
      "Epoch 1/10\n",
      "55528/55528 [==============================] - 398s 7ms/step - loss: 0.4894 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.4455 - val_sparse_categorical_accuracy: 0.8212\n",
      "Epoch 2/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.4088 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.4532 - val_sparse_categorical_accuracy: 0.8316\n",
      "Epoch 3/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.3765 - sparse_categorical_accuracy: 0.8559 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8355\n",
      "Epoch 4/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.8655 - val_loss: 0.4039 - val_sparse_categorical_accuracy: 0.8450\n",
      "Epoch 5/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.3305 - sparse_categorical_accuracy: 0.8748 - val_loss: 0.3947 - val_sparse_categorical_accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.3089 - sparse_categorical_accuracy: 0.8830 - val_loss: 0.4144 - val_sparse_categorical_accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "55528/55528 [==============================] - 395s 7ms/step - loss: 0.2868 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.4200 - val_sparse_categorical_accuracy: 0.8379\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MONITOR = 'val_sparse_categorical_accuracy'\n",
    "print('BATCH_SIZE is {}'.format(BATCH_SIZE))\n",
    "e_stopping = EarlyStopping(monitor=MONITOR, patience=3, verbose=1, mode='max', restore_best_weights=True)\n",
    "callbacks =  [e_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "   [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data = ([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:90: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14d63f500454dc5bbd03733de37d90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=6941.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6941/6941 [==============================] - 31s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4039655715944169, 0.8469961285591125]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples = convert_text_to_examples(test_text, test_label)\n",
    "\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "model.evaluate([test_input_ids, test_input_masks, test_segment_ids], test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_examples = convert_text_to_examples(pred_text, np.zeros(len(pred_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon2/bert/albert/albert-env/lib/python3.6/site-packages/ipykernel_launcher.py:90: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485c48cc82e748748ea415e8e367a3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=17353.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(pred_input_ids, pred_input_masks, pred_segment_ids, pred_labels\n",
    ") = convert_examples_to_features(tokenizer, pred_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17353/17353 [==============================] - 76s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([pred_input_ids, pred_input_masks, pred_segment_ids], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = label_encoder.classes_[np.argmax(prediction, axis =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cats', 'dogs', 'dogs', 'cats', 'cats', 'cats', 'cats', 'cats',\n",
       "       'dogs', 'dogs'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
